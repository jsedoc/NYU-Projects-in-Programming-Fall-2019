{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today we are going to learn about NLP (Natural Language Processing) using spaCy, an open source library for advanced NLP. \n",
    "\n",
    "### For more on spaCy, you can check out their site: https://spacy.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Natural Language Processing (NLP) is a subfield of Artificial Intelligence that deals with the 'understanding' of language. \n",
    "\n",
    "### For the purposes of this tutorial, we are going to look at the very basics of NLP, including using spaCy, an open-source NLP library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en import English # import the English language class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Similar to how you index through a list in Python, you can index through a Doc to retreive tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### You can also use 'span' which lets you take a slice of the Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What else can we do with spaCy? \n",
    "\n",
    "### Tokens have lots of attributes associated with them! For instance: \n",
    "\n",
    "1. is_alpha returns boolean indicating if a token consists of an alphanumeric value\n",
    "2. is_punct returns boolean indicating if a token is punctuation\n",
    "3. like_num returns boolean indicating if a token resembles a number \n",
    "\n",
    "### These are all called \"lexical attributes\" – they refer to the entry in the vocabulary and don't depend on the token's context. (More on that later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"The earnings report will be released at 5 pm sharp.\") # the text we want to work with \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How might that be helpful in real life? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise 1:\n",
    "\n",
    "### Imagine you are charged with reporting on a long press release, and you just want to know where in the document a percent increase or percent decrease is mentioned..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"In 2012, earnings were hovering around 60%, verus in 2019 where they are less than 4% – a 93% decrease.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using next_token, .like_num, .text, and find any percentage value mentiond in the doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## spaCy also has a handful of pre-built models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en') # loading in the package we just downloaded...\n",
    "\n",
    "doc = nlp(\"Adidas AG and Gap Inc. are among those at the end of the long supply chain that travel through \\\n",
    "           China’s northwest region of Xinjiang.\") # this is the text we want to analyze \n",
    "                                                   # that '\\' above just lets me split the text into a new \n",
    "                                                   # line in my notebook, and isn't part of the text itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## You can use ent.label_ to decipher entities..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"Adidas AG and Gap Inc. are among those at the end of the long supply chain that travel through \\\n",
    "           China’s northwest region of Xinjiang.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## To get quick definitions of common tags and labels, you can use \".explain\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## spaCy also lets you write rules to find words and/or phrases in a text. Similar to Regular Expressions, but with some major benefits unique to spaCy. \n",
    "\n",
    "### In particular, it allows you to match on Doc objects (not just strings), use the model's prediction capabilities, and match on tokens and token attributes. Match patterns in spaCy are comprised of lists of dictionaries, and each dictionary describes one token. \n",
    "\n",
    "### The keys in the dictionary are the names of the token attributes, and are mapped to their expected value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"New iPhone X release date leaked as Apple reveals pre-orders by mistake.\") # our text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### You'll note that the matcher returns a list of tuples. Each tuple consists of three values: \n",
    "\n",
    "    1. The match ID\n",
    "    2. The start index of the matched span\n",
    "    3. The end index of the matched span\n",
    "    \n",
    "### Fortunately, we can iterate over our matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Remember, you can also match on lexical attributes and token attributions. For instance, below we are going to look for five tokens: \n",
    "\n",
    "1. A token consisting of only digits\n",
    "2. Two, case-insensitive tokens for the words \"revenue\" and \"up\"\n",
    "3. Another token that consists of only digits\n",
    "4. A punctuation token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"Earnings are in today! 2019 Revenue up 45%! This is the highest revenue in 5 years.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## A note on Operators and Quantifiers.\n",
    "\n",
    "### Operators and Quantifiers let you define how often a token should be matched. \n",
    "\n",
    "### An Operator can have one of four values: \n",
    "\n",
    "1. An \"!\" negates the token, so it's matched 0 times\n",
    "2. A \"?\" makes the token optional, so it matches 0 or 1 times\n",
    "3. A \"+\" matches a token 1 or more times\n",
    "4. A \"*\" matches a token 0 or more times\n",
    "\n",
    "### Below, the \"?\" Operator makes the determiner token optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"Earnings are in today! 2019 Revenue up 45% for Company X. This is the highest revenue in 5 years.\")\n",
    "\n",
    "# note that our text above has changed... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luckily, Spacy also allows us to use Regular Expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "doc = nlp(\"Earnings are in today! 2019 Revenue up 45% for Company X. This is the highest revenue in 5 years.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "### Using the text provided below, create a pattern match that finds any news about a possible merger or acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Now let's delve into Vocabularies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### spaCy stores all shared data in a vocabulary, which includes words, as well as the labeled schemas for tags and entities. It also uses a hash function to generate an ID for each string, which is stored in a string store and is available via nlp.vocab.strings\n",
    "\n",
    "### This string store is ultimately a lookup table whereby you can look up a string to get its hash, or, look up a hash to get the string. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"I love coffee\") # our text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## spaCy even lets you compare two objects to predict how similar they are. \n",
    "\n",
    "### These objects can be documents, spans, or single tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import en_core_web_md # you only have to download it here if you didn't earlier\n",
    "\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### We can also compare two tokens: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Or, a document with a token: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And, last but not least, a span with a document: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## BeautifulSoup + spaCy\n",
    "\n",
    "### Now, let's use some of the BeautifulSoup to analyze some text from an online source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "r = requests.get('https://www.vice.com/en_us/article/a35ve5/what-it-would-take-for-the-next-president-to-cancel-all-student-debt') \n",
    "    # for more on the requests library check out this tutorial from RealPython: \n",
    "    # https://realpython.com/python-requests/\n",
    "            \n",
    "soup = BeautifulSoup(r.text,'html') # we are going to turn that URL into 'soup', aka, we are going to be \n",
    "                                    # able to see it's metadata For more on BeautifulSoup, check out: \n",
    "                                    # https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "            \n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now, we know that what we're interested in is the text of this article. So, let's see what that looks like in the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# find the text of our article \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Exercise 3\n",
    "\n",
    "### What if we want to know what entities are mentioned in the article? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise 4\n",
    "\n",
    "### What if we want to know the similarity between the first and last sentences of the aritcle? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## An enormous thank you to spaCy, whose existing online courses (https://course.spacy.io/chapter1) were the basis for this Jupyter-ized tutorial. For more information on spaCy's existing online course, check out https://github.com/ines/spacy-course#-faq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
