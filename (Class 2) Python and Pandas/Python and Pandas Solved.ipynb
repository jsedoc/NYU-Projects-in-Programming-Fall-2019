{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All material ©2019, Alex Siegman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Analysis with Python and Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd # importing the Pandas library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### For a full list of all the possible Pandas operations:  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Upload\n",
    "\n",
    "### The first step of data analysis is to actually get your data in the right place. \n",
    "\n",
    "### In order to upload our CSV (Commas Separated Values) into our Jupyter Notebook, we need to point our machine into the right folder, so to speak. \n",
    "\n",
    "### We can use Command Line commands to do so. (For more on the Command Line, check out \"Unix 101\" in the GitHub repo). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd # AKA, 'Print Working Directory' – tells us what folder I am in right now.\n",
    "\n",
    "# think of this like using your mouse to click into and out of folders on your desktop. \n",
    "# this is just bypassing that UI.\n",
    "\n",
    "# the '!' allows you to execute a shell command. Basically, you're working as if you would in \n",
    "# your terminal, but from the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls # list all of the files in the current directory (remember, directory = folder in UI world).."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that I'm in the right place (I see the CSV is in this folder), I can 'read' my CSV using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./SternTech_UserData.csv',encoding='utf-8') # read in the csv\n",
    "\n",
    "# we are setting our dataset equal to the value 'df'.\n",
    "# we can name this anything at all, it doesn't matter.\n",
    "# df is commonplace, though, and stands for 'data frame'.\n",
    "\n",
    "# you can ignore the 'encoding' piece for now, we'll get to that later on when we talk about web scraping. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's begin with a primary, exploratory analysis of our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 2000 # the way Jupyter Notebook tends to display the results of such queries isn't \n",
    "                                   # always helpful, but we can very easily change that.\n",
    "                                   # this will ensure we can view up to 2,000 rows without seeing elipses in the UI\n",
    "    \n",
    "pd.options.display.max_columns = 50 # try commenting out this last line ('max_columns =50') then run the cell below\n",
    "                                    # to see the difference this formatting makes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # this gets the first five rows of data in your data frame \n",
    "          # df.tail() will give you the last five rows\n",
    "          # if you want, you can choose any number - df.head(15) would give you the first 15 rows, for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df) # get a list of all the column names for your data frame\n",
    "\n",
    "# we'll discuss this later on, but note that a list is comprised of comma-separated values inside of square brackets\n",
    "# you can also use \"df.columns\" if you prefer, which will give you a similar output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop that \"unnamed\" column \n",
    "\n",
    "df = df.drop(df.columns[[0]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # get the basic statitical metrics for a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count() # get a count of the non-NA cells for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['sex'].value_counts() # see the non-NA cells for each value in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # just some basic information on the data types (strings, integers, floats, et. cetera) for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's important to note that our timestamp values are being stored as 'non-null object's' and not as timestamps, as we'd like. So, let's change that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit more primary exploratory analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample() # get a random sample value from the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] # select a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['age','sex']] # select multiple columns\n",
    "\n",
    "# .loc is used for labels/names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3] # get information on a single row \n",
    "\n",
    "# .iloc is used for position numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3,6] # get the value of the 7th column (ad_type) for the 4th row (3rd index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].mean() # get the mean of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"age\",ascending=False) # sort by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['age'] < 21] # see any rows where age < 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's a lot, I know. Next class we will continue using Pandas and some other Python libraries to delve further into the world of descriptive analytics. \n",
    "\n",
    "## For now, take some time to review this notebook and keep practicing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
